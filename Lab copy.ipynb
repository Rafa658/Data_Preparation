{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando módulos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# importando funções auxiliares\n",
    "from genre_code import genre_code\n",
    "from trees import id3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo os Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando os dataframes users, movies, ratings\n",
    "users = pd.read_csv('users.csv', sep=',')\n",
    "movies = pd.read_csv('movies.csv', sep=';')\n",
    "ratings = pd.read_csv('ratings.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratando o dataframe: users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserID Gender  Occupation    birthday\n",
      "0          1      F          10    4/1/2012\n",
      "1          2      M          16   9/21/1964\n",
      "2          3      M          15    4/3/1995\n",
      "3          4      M           7    5/8/1974\n",
      "4          5      M          20   6/18/1996\n",
      "...      ...    ...         ...         ...\n",
      "6035    6036      F          15  10/17/1995\n",
      "6036    6037      F           1   6/12/1975\n",
      "6037    6038      F           1   1/17/1963\n",
      "6038    6039      F           0   10/6/1977\n",
      "6039    6040      M           6    4/8/1988\n",
      "\n",
      "[6040 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# deletando colunas inúteis para a análise\n",
    "users = users.drop([\"name\", \"Zip-code\"], axis=1, errors='ignore')\n",
    "\n",
    "# printando o dataframe users\n",
    "print(users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraindo o ano das datas de nascimento para facilitar a obtenção da idade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserID Gender  Occupation birthday\n",
      "0          1      F          10     2012\n",
      "1          2      M          16     1964\n",
      "2          3      M          15     1995\n",
      "3          4      M           7     1974\n",
      "4          5      M          20     1996\n",
      "...      ...    ...         ...      ...\n",
      "6035    6036      F          15     1995\n",
      "6036    6037      F           1     1975\n",
      "6037    6038      F           1     1963\n",
      "6038    6039      F           0     1977\n",
      "6039    6040      M           6     1988\n",
      "\n",
      "[6040 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def splitIntoNumbers(string):\n",
    "    # a 3° posição dos string gerado retornará o ano de nascimento\n",
    "    return string.split('/')[2] \n",
    "\n",
    "# veja que não importa muito uma diferença de 1 ano nas datas de nascimento, que seria ocasionada pelo fato de a pessoa fazer aniversário antes ou depois de hoje. Pulamos essa parte porque não adicionaria muito à análise e apenas dificultaria o código.\n",
    "users['birthday'] = users['birthday'].apply(splitIntoNumbers)\n",
    "\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a idade de cada usuário baseado na data de nascimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAge(born):\n",
    "    today = date.today()\n",
    "    return today.year - int(born)\n",
    "\n",
    "users['age'] = users['birthday'].apply(calculateAge)\n",
    "\n",
    "users = users.drop('birthday', axis = 1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimindo o dataframe users tratado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserID Gender  Occupation  age\n",
      "0          1      F          10   10\n",
      "1          2      M          16   58\n",
      "2          3      M          15   27\n",
      "3          4      M           7   48\n",
      "4          5      M          20   26\n",
      "...      ...    ...         ...  ...\n",
      "6035    6036      F          15   27\n",
      "6036    6037      F           1   47\n",
      "6037    6038      F           1   59\n",
      "6038    6039      F           0   45\n",
      "6039    6040      M           6   34\n",
      "\n",
      "[6040 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trocando as idades para 'categorias', segundo como descrito no pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyAges(age):\n",
    "    if(age<18): age = 1\n",
    "    elif (age<25): age = 18\n",
    "    elif (age<35): age = 25\n",
    "    elif (age<45): age = 35\n",
    "    elif (age<50): age = 45\n",
    "    elif (age<56): age = 50\n",
    "    else: age = 56\n",
    "\n",
    "    return age\n",
    "\n",
    "users['age'] = users['age'].apply(classifyAges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserID Gender  Occupation  age\n",
      "0          1      F          10    1\n",
      "1          2      M          16   56\n",
      "2          3      M          15   25\n",
      "3          4      M           7   45\n",
      "4          5      M          20   25\n",
      "...      ...    ...         ...  ...\n",
      "6035    6036      F          15   25\n",
      "6036    6037      F           1   45\n",
      "6037    6038      F           1   56\n",
      "6038    6039      F           0   45\n",
      "6039    6040      M           6   25\n",
      "\n",
      "[6040 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratando o dataframe: movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MovieID                               Title  \\\n",
      "0           1                    Toy Story (1995)   \n",
      "1           2                      Jumanji (1995)   \n",
      "2           3             Grumpier Old Men (1995)   \n",
      "3           4            Waiting to Exhale (1995)   \n",
      "4           5  Father of the Bride Part II (1995)   \n",
      "...       ...                                 ...   \n",
      "3878     3948             Meet the Parents (2000)   \n",
      "3879     3949          Requiem for a Dream (2000)   \n",
      "3880     3950                    Tigerland (2000)   \n",
      "3881     3951             Two Family House (2000)   \n",
      "3882     3952               Contender, The (2000)   \n",
      "\n",
      "                            Genres Unnamed: 3  \n",
      "0      Animation|Children's|Comedy        NaN  \n",
      "1     Adventure|Children's|Fantasy        NaN  \n",
      "2                   Comedy|Romance        NaN  \n",
      "3                     Comedy|Drama        NaN  \n",
      "4                           Comedy        NaN  \n",
      "...                            ...        ...  \n",
      "3878                        Comedy        NaN  \n",
      "3879                         Drama        NaN  \n",
      "3880                         Drama        NaN  \n",
      "3881                         Drama        NaN  \n",
      "3882                Drama|Thriller        NaN  \n",
      "\n",
      "[3883 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# printando o dataframe movies\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluindo a coluna 'Unnamed: 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MovieID                               Title  \\\n",
      "0           1                    Toy Story (1995)   \n",
      "1           2                      Jumanji (1995)   \n",
      "2           3             Grumpier Old Men (1995)   \n",
      "3           4            Waiting to Exhale (1995)   \n",
      "4           5  Father of the Bride Part II (1995)   \n",
      "...       ...                                 ...   \n",
      "3878     3948             Meet the Parents (2000)   \n",
      "3879     3949          Requiem for a Dream (2000)   \n",
      "3880     3950                    Tigerland (2000)   \n",
      "3881     3951             Two Family House (2000)   \n",
      "3882     3952               Contender, The (2000)   \n",
      "\n",
      "                            Genres  \n",
      "0      Animation|Children's|Comedy  \n",
      "1     Adventure|Children's|Fantasy  \n",
      "2                   Comedy|Romance  \n",
      "3                     Comedy|Drama  \n",
      "4                           Comedy  \n",
      "...                            ...  \n",
      "3878                        Comedy  \n",
      "3879                         Drama  \n",
      "3880                         Drama  \n",
      "3881                         Drama  \n",
      "3882                Drama|Thriller  \n",
      "\n",
      "[3883 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# essa coluna foi gerada porque havia um ';' a mais no arquivo csv, que fazia o programa associar a uma coluna nova\n",
    "movies = movies.drop('Unnamed: 3', axis = 1, errors = 'ignore')\n",
    "\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando title e year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MovieID                        Genres                         title  \\\n",
      "0           1   Animation|Children's|Comedy                    Toy Story    \n",
      "1           2  Adventure|Children's|Fantasy                      Jumanji    \n",
      "2           3                Comedy|Romance             Grumpier Old Men    \n",
      "3           4                  Comedy|Drama            Waiting to Exhale    \n",
      "4           5                        Comedy  Father of the Bride Part II    \n",
      "...       ...                           ...                           ...   \n",
      "3878     3948                        Comedy             Meet the Parents    \n",
      "3879     3949                         Drama          Requiem for a Dream    \n",
      "3880     3950                         Drama                    Tigerland    \n",
      "3881     3951                         Drama             Two Family House    \n",
      "3882     3952                Drama|Thriller               Contender, The    \n",
      "\n",
      "      year  \n",
      "0     1995  \n",
      "1     1995  \n",
      "2     1995  \n",
      "3     1995  \n",
      "4     1995  \n",
      "...    ...  \n",
      "3878  2000  \n",
      "3879  2000  \n",
      "3880  2000  \n",
      "3881  2000  \n",
      "3882  2000  \n",
      "\n",
      "[3883 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafol\\AppData\\Local\\Temp\\ipykernel_7752\\3866909928.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  movies['year'] = movies['year'].str.replace(')','') # remove o caractere ')' que sobra\n"
     ]
    }
   ],
   "source": [
    "movies[['title', 'year', 'ph1', 'ph2']] = movies['Title'].str.split('(', expand=True)\n",
    "\n",
    "movies = movies.drop(['Title', 'ph1', 'ph2'], axis = 1, errors='ignore')\n",
    "\n",
    "movies['year'] = movies['year'].str.replace(')','') # remove o caractere ')' que sobra\n",
    "\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos atribuir a cada combinação de gêneros um valor. Atribuiremos potências de dois, pois a soma de 3 potências diferentes 2^n nunca pode ser igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MovieID  Genres                         title  year\n",
      "0           1      28                    Toy Story   1995\n",
      "1           2     266                      Jumanji   1995\n",
      "2           3    8208             Grumpier Old Men   1995\n",
      "3           4     144            Waiting to Exhale   1995\n",
      "4           5      16  Father of the Bride Part II   1995\n",
      "...       ...     ...                           ...   ...\n",
      "3878     3948      16             Meet the Parents   2000\n",
      "3879     3949     128          Requiem for a Dream   2000\n",
      "3880     3950     128                    Tigerland   2000\n",
      "3881     3951     128             Two Family House   2000\n",
      "3882     3952   32896               Contender, The   2000\n",
      "\n",
      "[3883 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# # PH1, PH2 e PH3 são Placeholders \n",
    "# movies[['Genre 1','Genre 2','Genre 3','PH1','PH2','PH3']] = movies['Genres'].str.split('|', expand = True)\n",
    "\n",
    "# movies = movies.drop(['Genres','PH1','PH2','PH3'], axis=1, errors='ignore')\n",
    "\n",
    "movies['Genres'] = movies['Genres'].apply(lambda x: x.split('|'))\n",
    "movies['Genres'] = movies['Genres'].apply(lambda x: genre_code(x))\n",
    "\n",
    "print(movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratando o dataframe: ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         UserID  MovieID  Rating  Timestamp\n",
      "0             1     1193       5  978300760\n",
      "1             1      661       3  978302109\n",
      "2             1      914       3  978301968\n",
      "3             1     3408       4  978300275\n",
      "4             1     2355       5  978824291\n",
      "...         ...      ...     ...        ...\n",
      "1000204    6040     1091       1  956716541\n",
      "1000205    6040     1094       5  956704887\n",
      "1000206    6040      562       5  956704746\n",
      "1000207    6040     1096       4  956715648\n",
      "1000208    6040     1097       4  956715569\n",
      "\n",
      "[1000209 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# printando o dataframe ratings\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando o dado Timestamp, que não é útil para nossa análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         UserID  MovieID  Rating\n",
      "0             1     1193       5\n",
      "1             1      661       3\n",
      "2             1      914       3\n",
      "3             1     3408       4\n",
      "4             1     2355       5\n",
      "...         ...      ...     ...\n",
      "1000204    6040     1091       1\n",
      "1000205    6040     1094       5\n",
      "1000206    6040      562       5\n",
      "1000207    6040     1096       4\n",
      "1000208    6040     1097       4\n",
      "\n",
      "[1000209 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.drop('Timestamp', axis=1, errors='ignore')\n",
    "\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos fundir os dataframes 'ratings' e 'users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         UserID Gender  Occupation  age  MovieID  Rating\n",
      "0             1      F          10    1     1193       5\n",
      "1             1      F          10    1      661       3\n",
      "2             1      F          10    1      914       3\n",
      "3             1      F          10    1     3408       4\n",
      "4             1      F          10    1     2355       5\n",
      "...         ...    ...         ...  ...      ...     ...\n",
      "1000204    6040      M           6   25     1091       1\n",
      "1000205    6040      M           6   25     1094       5\n",
      "1000206    6040      M           6   25      562       5\n",
      "1000207    6040      M           6   25     1096       4\n",
      "1000208    6040      M           6   25     1097       4\n",
      "\n",
      "[1000209 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "ru = pd.merge(users, ratings, on=['UserID'])    # ru de 'ratings' e 'users'\n",
    "print(ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundindo 'ru' e 'movies':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Gender  Occupation  age  MovieID  Rating  Genres  \\\n",
      "0            F          10    1     1193       5     128   \n",
      "1            M          16   56     1193       5     128   \n",
      "2            M          12   25     1193       4     128   \n",
      "3            M           7   25     1193       4     128   \n",
      "4            M           1   50     1193       5     128   \n",
      "...        ...         ...  ...      ...     ...     ...   \n",
      "1000204      M          17   18     2198       5      64   \n",
      "1000205      M          14   35     2703       3     128   \n",
      "1000206      M          17   18     2845       1     128   \n",
      "1000207      F          20   18     3607       5  131216   \n",
      "1000208      M           1   25     2909       4      64   \n",
      "\n",
      "                                         title  year  \n",
      "0             One Flew Over the Cuckoo's Nest   1975  \n",
      "1             One Flew Over the Cuckoo's Nest   1975  \n",
      "2             One Flew Over the Cuckoo's Nest   1975  \n",
      "3             One Flew Over the Cuckoo's Nest   1975  \n",
      "4             One Flew Over the Cuckoo's Nest   1975  \n",
      "...                                        ...   ...  \n",
      "1000204                           Modulations   1998  \n",
      "1000205                        Broken Vessels   1998  \n",
      "1000206                            White Boys   1999  \n",
      "1000207                     One Little Indian   1973  \n",
      "1000208  Five Wives, Three Secretaries and Me   1998  \n",
      "\n",
      "[1000209 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "rum = pd.merge(ru, movies, on=['MovieID'])\n",
    "\n",
    "rum = rum.drop('UserID', axis = 1, errors = 'ignore')\n",
    "\n",
    "print(rum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 3 2 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafol\\OneDrive\\Área de Trabalho\\Materiais\\CMC-13\\Lab 1 - Preparação de Dados\\entropy.py:13: RuntimeWarning: divide by zero encountered in log2\n",
      "  total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
      "c:\\Users\\rafol\\OneDrive\\Área de Trabalho\\Materiais\\CMC-13\\Lab 1 - Preparação de Dados\\entropy.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rafol\\OneDrive\\Área de Trabalho\\Materiais\\CMC-13\\Lab 1 - Preparação de Dados\\Lab.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/Lab.ipynb#ch0000031?line=0'>1</a>\u001b[0m tree \u001b[39m=\u001b[39m id3(rum\u001b[39m.\u001b[39;49mhead(\u001b[39m100\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39mRating\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/Lab.ipynb#ch0000031?line=1'>2</a>\u001b[0m pprint\u001b[39m.\u001b[39mpprint(tree)\n",
      "File \u001b[1;32mc:\\Users\\rafol\\OneDrive\\Área de Trabalho\\Materiais\\CMC-13\\Lab 1 - Preparação de Dados\\trees.py:74\u001b[0m, in \u001b[0;36mid3\u001b[1;34m(train_data_m, label)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=71'>72</a>\u001b[0m class_list \u001b[39m=\u001b[39m train_data[label]\u001b[39m.\u001b[39munique() \u001b[39m#getting unqiue classes of the label\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=72'>73</a>\u001b[0m \u001b[39mprint\u001b[39m(class_list)\n\u001b[1;32m---> <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=73'>74</a>\u001b[0m make_tree(tree, \u001b[39mNone\u001b[39;49;00m, train_data_m, label, class_list) \u001b[39m#start calling recursion\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=74'>75</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32mc:\\Users\\rafol\\OneDrive\\Área de Trabalho\\Materiais\\CMC-13\\Lab 1 - Preparação de Dados\\trees.py:62\u001b[0m, in \u001b[0;36mmake_tree\u001b[1;34m(root, prev_feature_value, train_data, label, class_list)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=58'>59</a>\u001b[0m \u001b[39mif\u001b[39;00m branch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# if it is expandable\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=59'>60</a>\u001b[0m     \u001b[39m# using the updated dataset\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=60'>61</a>\u001b[0m     feature_value_data \u001b[39m=\u001b[39m train_data[train_data[max_info_feature] \u001b[39m==\u001b[39m node]\n\u001b[1;32m---> <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=61'>62</a>\u001b[0m     make_tree(next_root, node, feature_value_data, label,\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=62'>63</a>\u001b[0m               class_list)\n",
      "File \u001b[1;32mc:\\Users\\rafol\\OneDrive\\Área de Trabalho\\Materiais\\CMC-13\\Lab 1 - Preparação de Dados\\trees.py:47\u001b[0m, in \u001b[0;36mmake_tree\u001b[1;34m(root, prev_feature_value, train_data, label, class_list)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=44'>45</a>\u001b[0m max_info_feature \u001b[39m=\u001b[39m find_most_informative_feature(train_data, label, class_list)  \u001b[39m# most informative feature\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=45'>46</a>\u001b[0m \u001b[39m# getting tree node and updated dataset\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=46'>47</a>\u001b[0m (tree, train_data) \u001b[39m=\u001b[39m generate_sub_tree(max_info_feature, train_data, label, class_list)\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=47'>48</a>\u001b[0m next_root \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m prev_feature_value \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:  \u001b[39m# add to intermediate node of the tree\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rafol\\OneDrive\\Área de Trabalho\\Materiais\\CMC-13\\Lab 1 - Preparação de Dados\\trees.py:9\u001b[0m, in \u001b[0;36mgenerate_sub_tree\u001b[1;34m(feature_name, train_data, label, class_list)\u001b[0m\n\u001b[0;32m      <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_sub_tree\u001b[39m(feature_name, train_data, label, class_list):\n\u001b[0;32m      <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=3'>4</a>\u001b[0m     \u001b[39m# feature_name: string, the name of the feature that we want to add to tree and shrink dataset (Ex. Outlook)\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=4'>5</a>\u001b[0m     \u001b[39m# train_data: a pandas dataframe/dataset\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=5'>6</a>\u001b[0m     \u001b[39m# label: string, name of the label of the dataframe (=Play Tennis)\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=6'>7</a>\u001b[0m     \u001b[39m# class_list: list, unique classes of the label (=[Yes, No]).\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=7'>8</a>\u001b[0m     \u001b[39m# returns: (dictionary, dataframe), the tree node with it’s branches and the updated dataset\u001b[39;00m\n\u001b[1;32m----> <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=8'>9</a>\u001b[0m     feature_value_count_dict \u001b[39m=\u001b[39m train_data[feature_name]\u001b[39m.\u001b[39mvalue_counts(\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=9'>10</a>\u001b[0m         sort\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)  \u001b[39m# dictionary of the count of unqiue feature value\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=10'>11</a>\u001b[0m     tree \u001b[39m=\u001b[39m {}  \u001b[39m# sub tree or node\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=12'>13</a>\u001b[0m     \u001b[39mfor\u001b[39;00m feature_value, count \u001b[39min\u001b[39;00m feature_value_count_dict\u001b[39m.\u001b[39miteritems():\n\u001b[0;32m     <a href='file:///c%3A/Users/rafol/OneDrive/%C3%81rea%20de%20Trabalho/Materiais/CMC-13/Lab%201%20-%20Prepara%C3%A7%C3%A3o%20de%20Dados/trees.py?line=13'>14</a>\u001b[0m         \u001b[39m# dataset with only feature_name = feature_value\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "tree = id3(rum.head(100), 'Rating')\n",
    "pprint.pprint(tree)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
